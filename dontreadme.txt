Struktur der sandbox

Es gibt eine Welt (grid), in der sich Objekte (Stone, Food oder Pixies) befinden

Die Pixies werden gesteuert von Genomen, welche eine fixe Anzahl an Genen beinhalten
Die Gene wiederum manifestieren eine Connection zwischen zwei Funktionen/Neuronen: sensory/Neuron, Neuron/Neuron, sensor/Action oder Neuron/Action
	
	MÃ¶glichkeit 1: Leichter, ohne Mutationen
	Ein Gen hat eine zufÃ¤llig festgelegt Connection (wie oben) und einen festen weight-Wert.

	MÃ¶glichkeit 2: Komplizierter, mit Mutation & Hamming-distance
	Ein Gen ist eine 32-bit-BinÃ¤rzahl, die nach einem festgelegten SchlÃ¼ssel zu einem Gen aus der Funktionenliste korreliert.
	DafÃ¼r sind diverse mapping- und Umrechnungsschritte notwendig (aber wurde alles schonmal von uns gecoded).
	Das Gen kÃ¶nnte dann fÃ¼r den Rest der Generation als Objekt wie in MÃ¶glichkeit 1 gespeichert werden.
	DafÃ¼r sind einzelne Mutationen an jedem bit mÃ¶glich, und eine Hamming-distance ist berechenbar.

Soweit so einfach: Der schwierigste Schritt ist die Verlinkung von sensory und Action Neurons Ã¼ber die inner Neurons.

	MÃ¶glichkeit 1: Leichter, mit reduzierter KomplexitÃ¤t
	Inner Neurons werden gekickt, es gibt nur direkte Verbindungen zwischen sensor und action-Neuronen

	MÃ¶glichkeit 2: Schwieriger, mit mehr MÃ¶glichkeit fÃ¼r komplexes emergentes Verhalten
	Inner Neurons bilden eine Zwischenebene, die sich auch selbst wieder ansteuern kÃ¶nnen.
	Dabei summiert ein inner Neuron alle Inputwerte (zwischengespeichert in einer Liste o.Ã¤.) und gibt einen Wert zwischen -1/1 aus.
	Der Outputwert wird im Neuron-Objekt selbst gespeichert
	Die Inputliste wird gecleart und neu mit dem outputwert des jetzigen Simsteps gefÃ¼llt. Dabei wird (z.B. als Tupel) sowohl das Ziel-Neuron (Nummer?)
	als auch der Ã¼bergebene Wert gespeichert, so kann ein Inner Neuron sich auch selbst im nÃ¤chsten Simstep ansteuern

	MÃ¶glichkeit 3: Komplett Objektorientiert
	Die Connections sind Objekte, die "Sensors", "Internals" und "Actions" sind eigene Klassen.
	Achtung: Jedes Pixie muss dabei eigene Objekte jeder im Genom kodierten Neuron-Klasse haben, damit individuelle input- und output-Werte 
	gespeichert werden kÃ¶nnen.
	Dabei verkÃ¶rpert jedes Neuron nur eine einzige Verhaltensschleife (--> functionality) und speichert die eigenen Input/output-Werte.
	Bei jedem Simstep wird der Input-Wert (falls gegeben) verarbeitet und der output-Wert (falls vorhanden) an das vorgeschriebene Neuron als neuer
	Input-Wert weitergeleitet.
	Manche Input-Werte werden so erst im nÃ¤chsten Simstep verarbeitet, aber wenn sensor- und action-Neuronen in der richtigen Reihenfolge aufgerufen
	werden sollte es auch noch im selben Simstep passieren kÃ¶nnen.
	Achtung 2: Inputwerte sollen im gleichen Simstep summiert werden, aber nicht Ã¼ber mehrere simSteps hinweg. DafÃ¼r sollen z.B. Internal Neurons
	aber schon ihre Output-Werte als Input-Werte im nÃ¤chsten Schritt behalten kÃ¶nnen (evtl. Ã¼ber einen Zwischenspeicher).

FÃ¼r die Ãœbersichtlichkeit kÃ¶nnen verschiedene Teile der Simulation in verschiedenen Dateien zwischengespeichert werden:

	Obwohl ne wird schwierig, weil z.B. action-Neuronen Funktionen aufrufen mÃ¼ssen, die sich auf die Hauptwelt zurÃ¼ckbeziehen


queueForMove: der moveX/Y-Wert wird jede Runde getracked und zum Schluss des simSteps automatisch in Bewegung umgesetzt (sofern nicht (0,0))


um zu checken welche Verbindungen invalide sind:
- Verbindungen ohne Output sollen gekickt werden
	dafÃ¼r wird fÃ¼r jede function im Sources-set geschaut, falls es ein internal Neuron ist (if in internal_dict.values() sollte gehen), ob es in der internal->internal oder internal->Action Liste einen Neurolink gibt der die Funktion als source hat

- inner Neurons die nur sich selbst ansteuern sollen gekickt werden
	dafÃ¼r wird fÃ¼r jedes internal Neuron (if in internal_dict.values()) geschaut, ob es in der internal->Action Liste einen Neurolink mit der Funktion als source hat. Wenn nicht wird es removed

- das funktioniert nicht bzw. ist viel zu umstÃ¤ndlich. Alternative: Wie D.Miller in jeder Funktion die variable "numOutputs", ("numInputs") und "numSelfInputs" tracken und anhand dessen entscheiden, welche Neuronen fliegen mÃ¼ssen.
DafÃ¼r muss einmal durch die source-bzw. sink-Liste iteriert werden und geschaut werden, was die neurolinks fÃ¼r sachen drin haben:
	- fÃ¼r jedes Neuron, das im source-Teil des neurolinks vorkommt, wird numOutputs erhÃ¶ht.
	- fÃ¼r jedes Neuron, das im sink-Teil vorkommt, wird numInputs erhÃ¶ht.
	- falls source und sink des neurolinks das gleiche Objekt ist, wird zusÃ¤tzlich numSelfInputs erhÃ¶ht.



Statt dass das Objekt beim Aufrufen des Neurolinks instanziert wird, erst mal nur Klasse speichern
FÃ¼r jedes Klassen objekt im Set in einem NEUEN set/liste ein objekt instanzieren --> individuelles Neuron
Auf dieses Neuron (1 uniques pro Pixie) kann sich dann bezogen werden


Problem: Da internal Neurone sowohl im sink- als auch im source-set instanziert werden, existieren sie als zwei unterschiedliche Objekte. Deshalb wird numOutputs z.B. auch doppelt gezÃ¤hlt. Das ist aber natÃ¼rlich auch blÃ¶d wenn sich Interneurone selbst ansteuern wollen.


Ich mÃ¶chte schauen,
	-welche neurolinks ich habe, fÃ¼r jedes neurolink
		-ermitteln was der source ist, auf das source-OBJEKT zugreifen (kein neues Objekt instanzieren)



Also es kommt manchmal noch dieser Error: 
File "c:\Users\ochse\Evolution-Simulieren\Biosim_sandbox.py", line 515, in executeGenes
    sink_obj.input += internal_output
TypeError: unsupported operand type(s) for +=: 'NoneType' and 'float'

was bedeutet dass in dieser Zeile:
            sink_obj = next((obj for obj in self.sinkNeurons if obj.__class__ == i_i_neurolink.sink), None)
kein Objekt fÃ¼r obj.__class__ == ...sink gefunden wird und stattdessen None zurÃ¼ckgegeben wird.

Das kann daran liegen, dass sinkNeurons und i_i_neurolink.sink nicht auf dem gleichen Stand sind, oder dass der Link versucht eine Connection anzusteuern die es eigentlich gar nicht mehr geben dÃ¼rfte (weil der sink schon gelÃ¶scht wurde). In dem Fall muss ich schauen dass das neural network sauberer aufgerÃ¤umt wird. Jetzt geh ich erstmal kacken


Wenn entweder die sourceNeurons-Liste oder die sinkNeurons-Liste leer ist, kann man davon ausgehen, dass es kein funktionierendes Genom gibt.
Dann kÃ¶nnte ein Bool functioningGenome = False gesetzt werden, und der executeGenome-Schritt Ã¼bersprungen werden. Das Pixie macht dann einfach gar nichts.


Im Moment wird das Genom in 6 Schritten "exprimiert", wobei auf jeder Ebene alle Neurone (falls vorhanden) abgegriffen werden und ausgefÃ¼hrt.
	--> das ganze funktioniert Ã¼ber for-Schleifen, die durch Listen iterieren

Alternativ kÃ¶nnte man auch einen mehr "kanalisierten" Approach nehmen, der eventuell FehleranfÃ¤lliger ist, aber andererseits flexibel ist bezÃ¼glich der LÃ¤nge der computeten Genome (wenn z.B. mehrere Internal Neurons auftreten).
DafÃ¼r wÃ¼rde nur auf der obersten Ebene (Sensors) durch die Liste iteriert werden und jeder Output weitergeleitet werden bis zu einem Action Neuron bzw. einem Internal Neuron das sich selbst feedet. Ganz zum Schluss (muss halt erkannt werden, wann Schluss ist) werden erst alle Action Neurone ausgefÃ¼hrt.
Das ganze hat ein bisschen was von rekursivem Coding, aber kÃ¶nnte ganz elegant werden. WÃ¼rde dann so ablaufen:

1. ein Sensor-Neuron gibt einen Output aus
2. In der s->i-Liste wird geschaut, welche Neurolinks das Neuron als source haben und diese transferieren den Output dann auch

	a) wenn das Sink-Neuron ein Internal Neuron ist (das nicht das Source-Neuron ist), wird das Neuron executed und der Output wieder in Schritt 2. in das sink-Neuron eingespeist
	b) andernfalls handelt es sich automatisch um ein Action Neuron oder ein self-linking Internal Neuron, der Output wird weitergeleitet und die loop wird gestoppt.
3. Alle Action Neuronen werden executed

^Problem damit: Bei jedem sensor-Neuron werden alle nachfolgenden internal Neurons sofort ausgefÃ¼hrt, ohne auf den Input anderer Neurone zu warten!

Andere, unkonventionelle MÃ¶glichkeit:
Wir tracken ja bei jedem Neuron die numInputs. Wir kÃ¶nnen daher jeden simStep einfach tracken, ob die benÃ¶tigte Anzahl an Inputs = numInputs-numSelfInputs erreicht wurde (indem bei jedem Input der Tracker eins hochgemacht wird), und wenn ja das Neuron AUTOMATISCH ausfÃ¼hren, ohne dass es dafÃ¼r von extern einen command brÃ¤uchte.
Auch action-Neurone kÃ¶nnen sofort ausgefÃ¼hrt werden, weil heikle Operationen wie move() ja sowieso gequeuet werden und erst am Ende des simSteps ausgefÃ¼hrt werden.
Nach jedem execute muss der inputTracker wieder auf 0 gesetzt werden!! und die Inputs selber auch.

DafÃ¼r mÃ¼ssen in der mainloop nur die sensorNeurons ausgefÃ¼hrt werden.

DafÃ¼r wÃ¤re es auch praktisch, wenn jedes (sensor/internal)Neuron selber wÃ¼sste, an wen es seine Outputs weiterleiten muss:
Am Anfang in der loadGenome-Funktion kÃ¶nnte durch die genes-Liste iteriert werden und jeder neurolink, der einem instanzierten Neuron als source entspricht, wird einem Attribut ownSinks oder so zugeordnet werden. Dann kann ein Neuron, wenn es executed wird, selbststÃ¤ndig den eigenen Output an alle sinks in der ownSinks-Liste weiterleiten (und natÃ¼rlich immer schÃ¶n den input-Tracker erhÃ¶hen) --> Problem: in den neurolinks werden ja keine Objekte, sondern Klassen gespeichert. In der ownSinks-Liste mÃ¼ssen aber Objekte stehen, ALSO muss wÃ¤hrend der loadGenome-Phase nicht der Neurolink selber zugeordnet werden, sondern das Neuron aus der sinkNeurons-Liste, das der Klasse des neurolink.sink entspricht. VoilÃ¡!


Ich hab total vergessen die weights einzubauen. Die Information geht auch verloren im Laufe von loadGenome, weil die Info, an welche sink-Neurons der Output Ã¼bertragen werden soll komplett von den neurolinks entkoppelt wird. Als LÃ¶sung mÃ¼sste die weight fÃ¼r jede Verbindung mit Ã¼bergeben werden. 
Aber das ist nicht schwer: Jedes sink-objekt wird ja einzeln zu ownSinks[] hinzugefÃ¼gt. Statt einzelne Objekte zu Ã¼bergeben kann einfach ein Tupel mit (sink_obj, weight) Ã¼bergeben werden - dann muss das Neuron bei transferOutputs nur das korrespondierende ownSinks[0]-Neuron ansteuern und den Output mit ownSinks[1] multiplizieren.

Super, das funktioniert alles!


NÃ¤chster Schritt: 
- eine function schreiben, die fÃ¼r jedes Pixie jeden simStep ausgefÃ¼hrt wird:
	- das Genom soll ausgefÃ¼hrt werden
	- gequeuete Funktionen (z.B. moveX, moveY) sollen ausgefÃ¼hrt werden 
		- dafÃ¼r wird jedes mal, wenn eine move-Funktion ausgefÃ¼hrt wird, das Pixie dem world.queueForMove -set hinzugefÃ¼gt. Dann kann am Schluss des simsteps Ã¼ber dieses set iteriert werden (in zufÃ¤lliger Reihenfolge, dann ist es sogar fair :^) ) und fÃ¼r alle Pixies darin die move-Funktion ausgefÃ¼hrt werden. Das gleiche mit nem anderen set fÃ¼r andere queue-Funktionen wie kill etc.

ErledigtğŸ‘

Als nÃ¤chstes sollen Pixies prozedural gespawnt werden kÃ¶nnen.
Das sollte nicht so schwer sein, das kann ich fast genauso machen wie bei PredatorPrey.
ZusÃ¤tzlich kÃ¶nnte ich an einer "Vererbungs"-Funktion arbeiten, die random Pixies aus world.inhabitants nimmt, ihre DNA kopiert und neue (in einer neuen world) Pixies instanziert, mit der DNA des vorherigen Pixies, und zwar so viele wie defaultNumPixies (es wird also immer wieder aufgefÃ¼llt). Die alte world oder zumindest seine .inhabitants und .Environment-Liste sollte nach MÃ¶glichkeit gelÃ¶scht werden, damit Speicherplatz freigegeben wird (safe nÃ¼tzlich bei langen Simulationen)


#######
To Do: Es wÃ¤re cool einen Weg zu haben die Farbe eines Pixies abhÃ¤ngig vom Genom zu machen, d.h. von der DNA.
Dabei muss der 32bit-string irgendwie in eine Farbe umgewandelt werden. Good to know: Unser 32bit string kodiert 4294967296 Zahlen, ein Hexcode (FFFFFF) nur 16^6=16777216 Zahlen, d.h. der 32bit-string kodiert 256 mal mehr Zahlen. Der gesamte 32bit-code kÃ¶nnte also als integer interpretiert, durch 256 geteilt werden und in Hexcode-Format umgeschrieben werden um eine unique Zahl zu bekommen (Problem: bits hinter der 8. Stelle sind dabei so gut wie irrelevant).
Als Workaround kÃ¶nnte der 32bit-string in 4 Teile Ã¡ 8 bits geteilt werden, die ersten drei (die letzen 8 Ziffern sind auch fÃ¼r das Pixie recht irrelevant) ergeben je eine Zahl zwischen 0 und 255 die als RGB-Wert gezÃ¤hlt werden kann. Nun kÃ¶nnte der Durchschnitt der Farben aller Gene fÃ¼r die Farbe des Pixies genommen werden. Problem: dann sind wahrscheinlich alle braun.
Also hier muss noch was besseres ausgetÃ¼ftelt werden
--> z.B. dass bei jeder Mutation tatsÃ¤chlich eine random Stelle vom Hexcode mutiert wird (radikal)



Um kontrolliert Populationen testen zu kÃ¶nnen, braucht es einen Weg, Die Genome aller inhabitants (vor dem selektieren) zu speichern und an anderer Stelle wieder einzufÃ¼ttern (z.B. bei firstGeneration()) --> check!

Orientierung des Pixies tracken - "facing"-variable
	- eine MÃ¶glichkeit wÃ¤re, die facing-Variable als Vektor des letzten Movements zu tracken
		- wenn "moveForward" getriggert wird, wird einfach derselbe Vektor als movement-urge Ã¼bergeben
		- wenn "moveBackwards" getriggert wird, wird das Vorzeichen von jedem element umgedreht.
		- wenn "moveLeft"/"moveRight" getriggert wird, wird es komplizierter.
	- andere MÃ¶glichkeit wÃ¤re, die facing-Variable als Winkel (rad) des letzten movements zu tracken. Dann mÃ¼sste bei jedem move der Winkel zuerst in eine Richtung Ã¼bersetzt werden und dieser dann an die movement-urge variable Ã¼bergeben.
		- wenn moveForward getriggert wird, wird die aktuelle facing-variable in einen Vektor Ã¼bersetzt
		- wenn moveBackwards getriggert wird, wird 1*pi draufgerechnet und dann in einen vektor Ã¼bersetzt
		- bei moveRight/Left wird jeweils pi/2 draufgerechnet bzw. abgezogen.
DafÃ¼r brauchen wir eine Function, die Vektoren in Winkel Ã¼bersetzt: getRelativeAngle braucht Vector Argument
Und eine Function, die Winkel in Vektoren Ã¼bersetzt: getNormalizedDirection braucht winkel Argument



KÃ¶nnte es sogar SEX geben??? Hierbei mÃ¼ssen zwei Pixies, die sich treffen und zufÃ¤llig sex "initiieren", z.B. die HÃ¤lfte aller .genes austauschen. Das hat keine Auswirkungen auf das neural network des betroffenen Pixies, aber auf die des nÃ¤chsten Erben
WÃ¤re aber gut wenn man sex auf 1 mal pro Generation limitiert.
--> Damit kÃ¶nnten wir Mullers Ratchet umgehen bzw. den "Ruby in the rubbish" finden!


Es fehlt noch ein searchRadius-Argument fÃ¼r searchNeighbourhood etc., die sich nicht auf defaultsearchRadius (existiert nicht mehr!) bezieht
--> fixed


#######
KÃ¶nnen wir die Neuron-classes auslagern?
	- die neuron_dicts mÃ¼ssten auf jeden Fall im alten Dokument bleiben, aber statt der 0: moveN - Schreibweise kÃ¶nnte es dann 0: neurons.moveN heiÃŸen - eigentlich sollte Python das gut erkennen sollen
	- hoffentlich funktionieren dann auch die ganzen compare-Funktionen noch (wie Neuron.__class__ == neurolink.source), das kÃ¶nnte man aber gut in nem anderen Dokument testen
	- die Objekte werden von der loadGenomes-Funktion instanziert und sofort einer Liste zugeordnet, das heiÃŸt sie sollten auch in der main Datei existieren
	- Letzte Frage bleibt, ob die execute-Funktionen in den Objekten, die sich auf Objekte des genomes/des pixies/der world etc. beziehen (z.B. xPosition das dann noch korrekt referenzieren kÃ¶nnen, aber das mÃ¼sste theoretisch auch kein Problem sein solange diese Sachen bei der Instanzierung mit Ã¼bergeben werden, und das werden sie ja mit attributedPixie.


ToDo:
- oldDNA tracken? D.h. wenn eine DNA-Mutation passiert, wird die alte beim genome abgespeichert. oldDNA wird auch bei Vererbung mit vererbt
- Ãœberlebensrate & DiversitÃ¤t jede Generation tracken und in Tabelle speichern
	- Ãœberlebensrate: len(inhabitants) nach applySelectioCriteria / numPixies
	- DiversitÃ¤t: Schwieriger, dafÃ¼r muss im Prinzip die DNA aller inhabitants einem Set zugeordnet werden und dann len(set) / numPixies
		aber: wenn Mutationen erlaubt, kann das zu trÃ¼gerisch hoher DiversitÃ¤t fÃ¼hren. Als Workaround kÃ¶nnte die Hamming distance fÃ¼r jedes set untereinander ausgerechnet werden und wenn zwei sehr nah sind nur als eins gezÃ¤hlt werden, oder komplizierter es werden die Verbindungen + Vorzeichen des weights ausgewertet. Das kÃ¶nnte aber wirklich viel code in Anspruch nehmen

Testen:
- ÃœberprÃ¼fen ob Internal Neurons wirklich funktionieren: Speichern sie ihre alten Outputs als Inputs und verwenden sie im nÃ¤chsten Simstep wieder?
- Funktioniert mutateGenes? ja


Bei D. Miller gibt es auch Internal Neurons, die ohne Input funktionieren (obwohl er im Video sagt, dass alles was sie machen ist Inputs zu summieren). Man kÃ¶nnte also Ã¼berlegen ob man ihnen Default Output werte gibt die sie raushauen wenn sie keinen Input bekommen. DafÃ¼r mÃ¼sste man auch deaktivieren dass I. Neurons entfernt werden wenn sie keine Input Connections haben. Oder man lÃ¤ssts
--> Das wÃ¼rde aber zu integrierten On/Off-Schaltern fÃ¼hren, weil wenn sich ein Neuron einmal selber ansteuert (und/oder keine sonstigen Inputs erhÃ¤lt), gibt es immer denselben Wert aus - bzw. der Wert schrumpft kontinuierlich, weil eine tanh-Funktion keinen Fixpunkt hat


AbsNeuron / PosNeuron als "Hochpassfilter": Gibt nur Output aus, wenn Input > 0, sonst 0. 
	-->AbsNeuron kÃ¶nnte auch negative Werte annehmen und immer de Betrag outputten


Funktion spawnFood(name, type, quantity, energyValue)
-> name kann irgendwas sein ("bananas", "food1")
-> type ist str , z.B. "random", "spread", "clumped". Jeder type generiert food-Verteilung auf andere weise, wie aus Ã–ko VL
-> quantity sagt wie viele food-Objekte insgesamt generiert werden
-> energyValue sagt wie viel energy man von jedem food-itemÂ kriegt